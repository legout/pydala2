{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Dataset Operations\n",
    "\n",
    "This notebook demonstrates the fundamental operations you can perform with PyDala2 datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from pathlib import Path\n",
    "\n",
    "# Import PyDala2 components\n",
    "from pydala.dataset import ParquetDataset, PyarrowDataset\n",
    "from pydala.table import PydalaTable\n",
    "from pydala.catalog import Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_data():\n",
    "    \"\"\"Create sample data for demonstration.\"\"\"\n",
    "    data = {\n",
    "        'id': range(1, 101),\n",
    "        'name': [f'Item_{i}' for i in range(1, 101)],\n",
    "        'category': ['A', 'B', 'C', 'D'] * 25,\n",
    "        'value': [i * 1.5 for i in range(100)],\n",
    "        'timestamp': pd.date_range('2024-01-01', periods=100, freq='D')\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Create sample data\n",
    "df = create_sample_data()\n",
    "print(f\"Created sample data with {len(df)} rows\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Creating Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary directory\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "temp_path = Path(temp_dir)\n",
    "\n",
    "print(f\"Using temporary directory: {temp_dir}\")\n",
    "\n",
    "# Method 1: Create from pandas DataFrame\n",
    "print(\"\\n1.1 Creating dataset from pandas DataFrame...\")\n",
    "dataset_path = temp_path / \"dataset_from_pandas\"\n",
    "ds = ParquetDataset.from_pandas(\n",
    "    df,\n",
    "    path=dataset_path,\n",
    "    partition_cols=['category']\n",
    ")\n",
    "print(f\"Created dataset at: {dataset_path}\")\n",
    "print(f\"Dataset contains {len(ds)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Create from PyArrow Table\n",
    "print(\"\\n1.2 Creating dataset from PyArrow Table...\")\n",
    "arrow_table = pa.Table.from_pandas(df)\n",
    "dataset_path2 = temp_path / \"dataset_from_arrow\"\n",
    "ds2 = ParquetDataset.from_arrow(\n",
    "    arrow_table,\n",
    "    path=dataset_path2,\n",
    "    row_group_size=25\n",
    ")\n",
    "print(f\"Created dataset at: {dataset_path2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 3: Create from existing parquet files\n",
    "print(\"\\n1.3 Creating dataset from existing parquet files...\")\n",
    "# Save individual parquet files\n",
    "for category in ['A', 'B', 'C', 'D']:\n",
    "    category_df = df[df['category'] == category]\n",
    "    category_path = temp_path / f\"raw_data/category={category}\"\n",
    "    category_path.mkdir(parents=True, exist_ok=True)\n",
    "    category_df.to_parquet(category_path / f\"data_{category}.parquet\")\n",
    "\n",
    "ds3 = ParquetDataset(temp_path / \"raw_data\")\n",
    "print(f\"Created dataset from {len(ds3.files)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Basic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataset info\n",
    "print(\"2.1 Dataset Information:\")\n",
    "print(f\" - Number of files: {len(ds.files)}\")\n",
    "print(f\" - Total rows: {len(ds)}\")\n",
    "print(f\" - Schema: {ds.schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PydalaTable for advanced operations\n",
    "table = ds.to_table()\n",
    "\n",
    "# Select columns\n",
    "print(\"\\n2.2 Column Selection:\")\n",
    "selected = table.select(['name', 'value', 'category'])\n",
    "print(f\"Selected columns: {selected.columns}\")\n",
    "selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data\n",
    "print(\"\\n2.3 Filtering Data:\")\n",
    "filtered = table.filter(table.value > 50)\n",
    "print(f\"Records with value > 50: {len(filtered)}\")\n",
    "filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate data\n",
    "print(\"\\n2.4 Aggregation:\")\n",
    "df_filtered = filtered.to_pandas()\n",
    "agg_result = df_filtered.groupby('category')['value'].agg(['mean', 'sum', 'count'])\n",
    "print(f\"Aggregation by category:\")\n",
    "agg_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Working with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom metadata\n",
    "print(\"3.1 Adding Custom Metadata:\")\n",
    "ds.metadata.update({\n",
    "    'description': 'Sample dataset for demonstration',\n",
    "    'created_by': 'PyDala2 examples',\n",
    "    'version': '1.0',\n",
    "    'tags': ['sample', 'demo', 'test']\n",
    "})\n",
    "ds.save_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read metadata\n",
    "print(\"\\n3.2 Reading Metadata:\")\n",
    "print(f\"Description: {ds.metadata.get('description')}\")\n",
    "print(f\"Created by: {ds.metadata.get('created_by')}\")\n",
    "print(f\"Version: {ds.metadata.get('version')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work with schema metadata\n",
    "print(\"\\n3.3 Schema Information:\")\n",
    "for field in ds.schema:\n",
    "    print(f\" - {field.name}: {field.type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Using the Catalog System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a catalog\n",
    "catalog_path = temp_path / \"catalog.yaml\"\n",
    "catalog = Catalog(catalog_path)\n",
    "\n",
    "# Create multiple datasets\n",
    "# Dataset 1: Full data\n",
    "ds1 = ParquetDataset.from_pandas(\n",
    "    df,\n",
    "    path=temp_path / \"full_dataset\"\n",
    ")\n",
    "catalog.register_dataset(\"full_data\", ds1)\n",
    "\n",
    "# Dataset 2: Filtered data\n",
    "df_filtered = df[df['category'].isin(['A', 'B'])]\n",
    "ds2 = ParquetDataset.from_pandas(\n",
    "    df_filtered,\n",
    "    path=temp_path / \"filtered_dataset\"\n",
    ")\n",
    "catalog.register_dataset(\"filtered_data\", ds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List datasets\n",
    "print(\"4.1 Registered Datasets:\")\n",
    "for name in catalog.list_datasets():\n",
    "    print(f\" - {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve dataset\n",
    "print(\"\\n4.2 Retrieving Dataset:\")\n",
    "retrieved_ds = catalog.get_dataset(\"full_data\")\n",
    "print(f\"Retrieved dataset has {len(retrieved_ds)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save catalog\n",
    "catalog.save()\n",
    "print(f\"\\n4.3 Catalog saved to: {catalog_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Advanced Table Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to different formats\n",
    "print(\"5.1 Format Conversions:\")\n",
    "\n",
    "# To pandas\n",
    "pdf = table.to_pandas()\n",
    "print(f\"Converted to pandas: {type(pdf)} with shape {pdf.shape}\")\n",
    "\n",
    "# To PyArrow\n",
    "arrow_table = table.to_arrow()\n",
    "print(f\"Converted to PyArrow: {type(arrow_table)} with {arrow_table.num_rows} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scanner for efficient reading\n",
    "print(\"\\n5.2 Using Scanner:\")\n",
    "scanner = table.to_arrow_scanner(\n",
    "    columns=['id', 'name', 'value'],\n",
    "    filter=pa.dataset.field('value') > 75\n",
    ")\n",
    "\n",
    "# Read in batches\n",
    "batch_count = 0\n",
    "total_rows = 0\n",
    "for batch in scanner.to_batches():\n",
    "    batch_count += 1\n",
    "    total_rows += batch.num_rows\n",
    "\n",
    "print(f\"Read {batch_count} batches with {total_rows} total rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Head operation\n",
    "print(\"\\n5.3 Head Operation:\")\n",
    "head_data = table.head(5)\n",
    "head_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Remove temporary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(temp_dir)\n",
    "print(f\"Cleaned up temporary directory: {temp_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}